{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from xgboost import XGBClassifier\n",
    "import wandb\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(dataset_name, dropna=True, fillna_value=''):\n",
    "    df = pd.read_csv(f\"data/{dataset_name}.csv\")\n",
    "    \n",
    "    if dropna:\n",
    "        df.dropna(inplace=True)\n",
    "    else:\n",
    "        df.fillna(fillna_value, inplace=True)\n",
    "\n",
    "    df.drop(['ID'], axis=1, inplace=True) # remove useless data\n",
    "\n",
    "    df['Rating'] = df['Rating'] - 1 # make y 0-indexed\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_df('train', dropna=True)\n",
    "df_valid = get_df('valid', dropna=False)\n",
    "df_test = get_df('test', dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Rating'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "keep_stop_words = ['not', 'no', 'against', 'above', 'below']\n",
    "for word in keep_stop_words:\n",
    "    stop_words.remove(word)\n",
    "\n",
    "punctuation_to_remove = set(string.punctuation)\n",
    "punctuation_to_remove.remove('!')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize_text(text: str):\n",
    "    if (not isinstance(text, str)):\n",
    "        raise ValueError(f\"The text {text} isn't a string!\")\n",
    "\n",
    "    # Change 't to 'not'\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    # Remove punctuation except '!'\n",
    "    text = ''.join([char for char in text if char not in punctuation_to_remove])\n",
    "    # Remove numbers\n",
    "    text = re.sub(r\"\\d\", \"\", text)\n",
    "    \n",
    "    text = text.lower()\n",
    "\n",
    "    word_tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    filtered_words_tokens = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "    lemmatized_text = [lemmatizer.lemmatize(w) for w in filtered_words_tokens]\n",
    "    \n",
    "    return ' '.join(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_X(X):\n",
    "    return [tokenize_text(text) for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_vectorizer(X_train, ngram_range=(1, 1), max_features=None):\n",
    "    # settings inspired by https://www.linkedin.com/pulse/another-twitter-sentiment-analysis-python-part-5-tfidf-ricky-kim/\n",
    "    # TODO consider options: max_df=0.9, min_df=2\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "    tfidf_vectorizer.fit(get_tokenized_X(X_train))\n",
    "\n",
    "    return tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_vectorizer(X_train, ngram_range=(1, 1)):\n",
    "    count_vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "    count_vectorizer.fit(get_tokenized_X(X_train))\n",
    "\n",
    "    return count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorized_X(X, vectorizer):\n",
    "    tokenized_X = get_tokenized_X(X)\n",
    "\n",
    "    vectorized_X = vectorizer.transform(tokenized_X)\n",
    "\n",
    "    return vectorized_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_tokenizer_applied(df, columns):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        print(f\"Applying tokenize_text() to column {column}\")\n",
    "        df[column] = df[column].apply(tokenize_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pp = get_df_tokenizer_applied(df_train, ['Title', 'Review Text'])\n",
    "df_valid_pp = get_df_tokenizer_applied(df_valid, ['Title', 'Review Text'])\n",
    "df_test_pp = get_df_tokenizer_applied(df_test, ['Title', 'Review Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pp.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ohe_for_df_column(df_column):\n",
    "    ohe_column = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    ohe_column.fit(df_column.to_numpy().reshape(-1, 1))\n",
    "    return ohe_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_divisionname = get_ohe_for_df_column(df_train_pp['Division Name'])\n",
    "ohe_departmentname = get_ohe_for_df_column(df_train_pp['Department Name'])\n",
    "ohe_classname = get_ohe_for_df_column(df_train_pp['Class Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_with_ohe_column(df, ohe_column_name, ohe):\n",
    "    ohe_column_encoded = ohe.transform(df[ohe_column_name].to_numpy().reshape(-1, 1))\n",
    "\n",
    "    ohe_df = pd.DataFrame(ohe_column_encoded.tolist(), columns=ohe.get_feature_names_out(input_features=[ohe_column_name]), dtype=int)\n",
    "    # reset_index() is necessary here: https://stackoverflow.com/questions/50368145/pandas-concat-increases-number-of-rows\n",
    "    # drop=True as well: https://stackoverflow.com/questions/12203901/pandas-crashes-on-repeated-dataframe-reset-index\n",
    "    new_df = pd.concat([df.reset_index(drop=True), ohe_df], axis=1).drop([ohe_column_name], axis=1)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_with_ohe_columns(df):\n",
    "    df = get_df_with_ohe_column(df, 'Division Name', ohe_divisionname)\n",
    "    df = get_df_with_ohe_column(df, 'Department Name', ohe_departmentname)\n",
    "    df = get_df_with_ohe_column(df, 'Class Name', ohe_classname)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_categorical_value_ohe = True\n",
    "\n",
    "if (do_categorical_value_ohe):\n",
    "    df_train_wo_cat = get_df_with_ohe_columns(df_train_pp)\n",
    "    df_valid_wo_cat = get_df_with_ohe_columns(df_valid_pp)\n",
    "    df_test_wo_cat = get_df_with_ohe_columns(df_test_pp)\n",
    "else:\n",
    "    df_train_wo_cat = df_train_pp.drop(['Division Name', 'Department Name', 'Class Name'], axis=1)\n",
    "    df_valid_wo_cat = df_valid_pp.drop(['Division Name', 'Department Name', 'Class Name'], axis=1)\n",
    "    df_test_wo_cat = df_test_pp.drop(['Division Name', 'Department Name', 'Class Name'], axis=1)\n",
    "\n",
    "df_train_wo_cat.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3)) # 0.618\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 10000) # 0.622\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 7000) # 0.619\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 4000) # 0.617\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 1000) # 0.615\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 15000) # 0.617\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 20000) # 0.617\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 8500) # 0.623\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 9000) # 0.622\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 8000) # 0.623\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 7500) # 0.622\n",
    "# title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 8250) # 0.622\n",
    "title_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Title'], (1, 3), 8000)\n",
    "\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 8000) # 0.636\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 5000) # 0.632\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 3000) # 0.635\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 1000) # 0.635\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 500) # 0.627\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 10000) # 0.639\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 15000) # 0.640\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 20000) # 0.639\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 25000) # 0.639\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 17500) # 0.640\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 12500) # 0.641\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 14000) # 0.642\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 14500) # 0.640\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 13000) # 0.643\n",
    "# reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 13500) # 0.640\n",
    "reviewtext_vectorizer = get_tfidf_vectorizer(df_train_wo_cat['Review Text'], (1, 2), 13000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_title = get_vectorized_X(df_train_wo_cat['Title'], title_vectorizer)\n",
    "X_valid_title = get_vectorized_X(df_valid_wo_cat['Title'], title_vectorizer)\n",
    "\n",
    "X_train_reviewtext = get_vectorized_X(df_train_wo_cat['Review Text'], reviewtext_vectorizer)\n",
    "X_valid_reviewtext = get_vectorized_X(df_valid_wo_cat['Review Text'], reviewtext_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_title = df_train_wo_cat['Rating'].tolist()\n",
    "y_valid_title = df_valid_wo_cat['Rating'].tolist()\n",
    "\n",
    "y_train_reviewtext = df_train_wo_cat['Rating'].tolist()\n",
    "y_valid_reviewtext = df_valid_wo_cat['Rating'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train_title), len(y_train_title))\n",
    "print(len(X_valid_title), len(y_valid_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_title = MultinomialNB() # Accuracy:  0.5936967632027257\n",
    "# nb_title.fit(X_train_title, y_train_title)\n",
    "# y_pred_title = nb_title.predict(X_valid_title)\n",
    "# accuracy = accuracy_score(y_valid_title, y_pred_title)\n",
    "# print(\"Naive Bayes 'Title Sentiment' Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_title = LogisticRegression(random_state=random_state, solver=\"saga\", max_iter=200) # Accuracy:  0.623\n",
    "logreg_title.fit(X_train_title, y_train_title)\n",
    "y_pred_title = logreg_title.predict(X_valid_title)\n",
    "accuracy = accuracy_score(y_valid_title, y_pred_title)\n",
    "print(\"Logistic Regression 'Title Sentiment' Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_reviewtext = MultinomialNB() # Accuracy:  0.608\n",
    "# nb_reviewtext.fit(X_train_reviewtext, y_train_reviewtext)\n",
    "# y_pred_reviewtext = nb_reviewtext.predict(X_valid_reviewtext)\n",
    "# accuracy = accuracy_score(y_valid_reviewtext, y_pred_reviewtext)\n",
    "# print(\"Naive Bayes 'Review Text' Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_reviewtext = XGBClassifier(random_state=random_state, objective='multi:softmax') # Accuracy:  0.615 (3.5m runtime) with 8000 features\n",
    "# xgb_reviewtext.fit(X_train_reviewtext, y_train_reviewtext)\n",
    "# y_pred_reviewtext = xgb_reviewtext.predict(X_valid_reviewtext)\n",
    "# accuracy = accuracy_score(y_valid_reviewtext, y_pred_reviewtext)\n",
    "# print(\"XGBoost 'Review Text Sentiment' Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_reviewtext = LogisticRegression(random_state=random_state, solver=\"saga\", max_iter=200) # Accuracy:  0.643\n",
    "logreg_reviewtext.fit(X_train_reviewtext, y_train_reviewtext)\n",
    "y_pred_reviewtext = logreg_reviewtext.predict(X_valid_reviewtext)\n",
    "accuracy = accuracy_score(y_valid_reviewtext, y_pred_reviewtext)\n",
    "print(\"Logistic Regression 'Review Text Sentiment' Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_reviewtext.shape # (2348, 212416)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df: pd.DataFrame):\n",
    "    vectorized_title = title_vectorizer.transform(df['Title']).toarray()\n",
    "    df['Title Sentiment'] = logreg_title.predict(vectorized_title)\n",
    "    # df = pd.DataFrame(vectorized_title, index=df.index)\n",
    "\n",
    "    vectorized_reviewtext = reviewtext_vectorizer.transform(df['Review Text']).toarray()\n",
    "    df['Review Text Sentiment'] = logreg_reviewtext.predict(vectorized_reviewtext)\n",
    "    # df = pd.DataFrame(vectorized_reviewtext, index=df.index)\n",
    "\n",
    "    # df_with_title_and_text = pd.concat([df, title_df, text_df], axis=1)\n",
    "\n",
    "    df.drop(['Title'], axis=1, inplace=True)\n",
    "    df.drop(['Review Text'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('preprocessing train data')\n",
    "df_train_final = preprocess_df(df_train_wo_cat)\n",
    "print('preprocessing valid data')\n",
    "df_valid_final = preprocess_df(df_valid_wo_cat)\n",
    "print('preprocessing test data')\n",
    "df_test_final = preprocess_df(df_test_wo_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train_final['Rating'].values\n",
    "y_valid = df_valid_final['Rating'].values\n",
    "y_test = df_test_final['Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final.drop(['Rating'], axis=1, inplace=True)\n",
    "X_train = df_train_final.values\n",
    "df_valid_final.drop(['Rating'], axis=1, inplace=True)\n",
    "X_valid = df_valid_final.values\n",
    "df_test_final.drop(['Rating'], axis=1, inplace=True)\n",
    "X_test = df_test_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_tab = RandomForestClassifier(random_state=random_state, n_estimators=1000)\n",
    "# rf_tab.fit(X_train, y_train)\n",
    "# y_preds = rf_tab.predict(X_valid)\n",
    "# rf_tab_accuracy = accuracy_score(y_valid, y_preds)\n",
    "# print(f\"Random Forest tabular accuracy: {rf_tab_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbt_tab = GradientBoostingClassifier(random_state=random_state, n_estimators=1000)\n",
    "# gbt_tab.fit(X_train, y_train)\n",
    "# y_preds = gbt_tab.predict(X_valid)\n",
    "# gbt_tab_accuracy = accuracy_score(y_valid, y_preds)\n",
    "# print(f\"Gradient Boosting tabular accuracy: {gbt_tab_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # logreg_tab = LogisticRegression(random_state=random_state, solver=\"saga\", max_iter=20000) # accuracy: 0.662\n",
    "# logreg_tab = LogisticRegression(random_state=random_state, solver=\"lbfgs\", max_iter=20000) # accuracy: 0.676\n",
    "# logreg_tab.fit(X_train, y_train)\n",
    "# y_preds = logreg_tab.predict(X_valid)\n",
    "# logreg_tab_accuracy = accuracy_score(y_valid, y_preds)\n",
    "# print(f\"Logistic Regression tabular accuracy: {logreg_tab_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bst_tab = XGBClassifier(random_state=random_state, n_estimators=9, max_depth=2, learning_rate=.9, objective='multi:softmax') # 0.664\n",
    "# bst_tab = XGBClassifier(random_state=random_state, objective='multi:softmax') # 0.662\n",
    "# bst_tab.fit(X_train, y_train)\n",
    "# y_preds = bst_tab.predict(X_valid)\n",
    "# bst_tab_accuracy = accuracy_score(y_valid, y_preds)\n",
    "# print(f\"XGBoost tabular accuracy before hyperparameter tuning: {bst_tab_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # helpful article on XGBoost hyperparameter optimization using hyperopt: https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning/notebook\n",
    "\n",
    "# import wandb\n",
    "# from hyperopt import STATUS_OK, fmin, hp, tpe, Trials\n",
    "# import copy\n",
    "\n",
    "# \"\"\"\n",
    "# hp.choice(label, options) — Returns one of the options, which should be a list or tuple.\n",
    "# hp.randint(label, upper) — Returns a random integer between the range [0, upper).\n",
    "# hp.uniform(label, low, high) — Returns a value uniformly between low and high.\n",
    "# hp.quniform(label, low, high, q) — Returns a value round(uniform(low, high) / q) * q, i.e it rounds the decimal values and returns an integer.\n",
    "# hp.normal(label, mean, std) — Returns a real value that's normally-distributed with mean and standard deviation sigma.\n",
    "\n",
    "# use uniform for a range from to (float)\n",
    "# use uniform for a range from to (float but just 1 decimal 0)\n",
    "# use choice hack (hp.choice('n_estimators', np.arange(1, 500, dtype=int))) for range from to with no decimal (int)\n",
    "# \"\"\"\n",
    "\n",
    "# def fix_xgb_args(obj):\n",
    "#     keys_to_remove = ['early_stopping_rounds'] # only relevant during train time, not inference time\n",
    "#     keys_requiring_ints = ['max_depth']\n",
    "#     new_obj = copy.deepcopy(obj)\n",
    "#     for key, value in obj.items():\n",
    "#         if key in keys_to_remove:\n",
    "#             new_obj.pop(key)\n",
    "#         if key in keys_requiring_ints:\n",
    "#             new_obj[key] = int(value)\n",
    "#     return new_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(hyperparams):\n",
    "#     clf = XGBClassifier(\n",
    "#         **fix_xgb_args(hyperparams),\n",
    "#         objective = 'multi:softmax',\n",
    "#         random_state = random_state\n",
    "#     )\n",
    "    \n",
    "#     clf.fit(\n",
    "#         X_train, y_train,\n",
    "#         eval_set = [(X_valid, y_valid)], \n",
    "#         verbose = False\n",
    "#     )\n",
    "    \n",
    "#     pred = clf.predict(X_valid)\n",
    "#     accuracy = accuracy_score(y_valid, pred)\n",
    "#     loss = 1 - accuracy\n",
    "\n",
    "#     wandb.log({\"accuracy\": accuracy, \"loss\": loss})\n",
    "\n",
    "#     return {'loss': loss, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"trees-vs-nns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_2_20 = np.arange(2, 20, dtype=int)\n",
    "# range_2_100 = np.arange(2, 100, dtype=int)\n",
    "\n",
    "# hyperparams = {\n",
    "#     'max_depth': hp.choice('max_depth', range_2_20),\n",
    "#     'gamma': hp.quniform('gamma', 0, 1, 0.01),\n",
    "#     'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01),\n",
    "#     'min_child_weight' : hp.quniform('min_child_weight', 1, 20, 1),\n",
    "#     'subsample': hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "#     'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "#     'learning_rate': hp.quniform('learning_rate', 0.01, 0.99, 0.01),\n",
    "#     'n_estimators': hp.choice('n_estimators', range_2_100),\n",
    "# }\n",
    "\n",
    "# trials = Trials()\n",
    "\n",
    "# best_hyperparams = fmin(\n",
    "#     fn = objective,\n",
    "#     space = hyperparams,\n",
    "#     algo = tpe.suggest,\n",
    "#     max_evals = 500,\n",
    "#     trials = trials,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train and fit on best hyperparameters\n",
    "# bst_tab_hat = XGBClassifier(random_state=random_state, objective='multi:softmax', **fix_xgb_args(best_hyperparams))\n",
    "# bst_tab_hat.fit(X_train, y_train)\n",
    "\n",
    "# # test on valid dataset\n",
    "# y_preds = bst_tab_hat.predict(X_valid)\n",
    "# bst_tab_hat_accuracy = accuracy_score(y_valid, y_preds)\n",
    "# print(f\"XGBoost tabular accuracy: {bst_tab_hat_accuracy}\")\n",
    "# print(\"hyperparameters used:\", fix_xgb_args(best_hyperparams))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test on test dataset\n",
    "# y_preds_test = bst_tab_hat.predict(X_test)\n",
    "# bst_tab_hat_accuracy_test = accuracy_score(y_test, y_preds_test)\n",
    "# print(f\"XGBoost tabular accuracy: {bst_tab_hat_accuracy_test}\")\n",
    "\n",
    "# lr_y_preds_test = logreg_tab.predict(X_test)\n",
    "# lr_logreg_tab_accuracy = accuracy_score(y_test, lr_y_preds_test)\n",
    "# print(f\"Logistic Regression tabular accuracy: {lr_logreg_tab_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Illegal\" optimizations after using the last unseen data. Goal: use wandb for the hyperparameter sweep instead of hyperopt and create one of these fancy parallel coordinates diagram: https://docs.wandb.ai/assets/images/intro_what_it_is-8462e8215e06544eaa40dfdfe656d03d.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'trees-vs-nns'\n",
    "sweep_name = f\"{project_name}-sweep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb sweep configuration keys https://docs.wandb.ai/guides/sweeps/define-sweep-configuration#configuration-keys\n",
    "\n",
    "sweep_config = {\n",
    "    \"name\": sweep_name,\n",
    "    \"metric\": { \"name\": \"accuracy\", \"goal\": \"maximize\" },\n",
    "    \"method\": \"bayes\",\n",
    "    \"parameters\": {\n",
    "        'max_depth': { \"values\": np.arange(2, 20).tolist() },\n",
    "        'gamma': {'min': 0.0, 'max': 1.0},\n",
    "        'colsample_bytree' : {'min': 0.1, 'max': 1.0},\n",
    "        'min_child_weight' : { \"values\": np.arange(1, 20).tolist() },\n",
    "        'subsample': {'min': 0.1, 'max': 1.0},\n",
    "        'eta': {'min': 0.025, 'max': 0.5},\n",
    "        'learning_rate': {'min': 0.01, 'max': 0.99},\n",
    "        'n_estimators': { \"values\": np.arange(2, 100).tolist() },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(hyperparams):\n",
    "    clf = XGBClassifier(\n",
    "        **hyperparams,\n",
    "        objective = 'multi:softmax',\n",
    "        random_state = random_state\n",
    "    )\n",
    "    \n",
    "    clf.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set = [(X_valid, y_valid)], \n",
    "        verbose = False\n",
    "    )\n",
    "    \n",
    "    pred = clf.predict(X_valid)\n",
    "\n",
    "    accuracy = accuracy_score(y_valid, pred)\n",
    "    print(f\"accuracy: {accuracy}\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    wandb.init(project=project_name)\n",
    "    accuracy = objective(wandb.config)\n",
    "    wandb.log({'accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_SILENT']=\"true\" # avoids a lengthy log per sweep\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=project_name)\n",
    "wandb.agent(sweep_id, function=main, count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "sweep = api.sweep(f\"trees-vs-nns/{sweep_id}\")\n",
    "best_run = sweep.best_run()\n",
    "best_run_hyperparams = best_run.config\n",
    "best_run_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and fit on best hyperparameters\n",
    "bst_tab_hat = XGBClassifier(random_state=random_state, objective='multi:softmax', **best_run_hyperparams)\n",
    "bst_tab_hat.fit(X_train, y_train)\n",
    "\n",
    "# test on valid dataset\n",
    "y_preds = bst_tab_hat.predict(X_valid)\n",
    "bst_tab_hat_accuracy = accuracy_score(y_valid, y_preds)\n",
    "print(f\"XGBoost tabular accuracy: {bst_tab_hat_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on test dataset\n",
    "y_preds_test = bst_tab_hat.predict(X_test)\n",
    "bst_tab_hat_accuracy_test = accuracy_score(y_test, y_preds_test)\n",
    "print(f\"XGBoost tabular accuracy: {bst_tab_hat_accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2dbbb6cd59b3dbdf4da55c2d28b7f7ae42791a8b99736a7739fce4258f4b207c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
